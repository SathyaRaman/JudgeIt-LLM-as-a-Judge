## Evaluation done on two types of workflows:
1. SDR+ flow
2. Self-driving flow

## Evaluation done with the following methods:
1. Blackbox (Agent-level evaluation)
2. Whitebox (Workflow-level evaluation)
3. Negative testing

### Blackbox evaluation implementation for SDR+ workflow
Focuses on evaluating the output quality and completeness of each SDR+ workflow agent — Comms, Research, Product, and Chrono — without inspecting their internal logic.

Each agent output is compared against a ground truth reference, and assigned a normalized score based on content inclusion, factual accuracy, and task completion.

#### Score system:
Research, Product, Chrono: 0–1
0: Output incomplete or factually inaccurate
1: Output complete, accurate, and aligned with ground truth (included all details from relevant tools)
Comms: 1–3
1: Poor clarity, off-tone, or missing key elements
2: Adequate but minor content issues
3: Excellent — clear, accurate, well-structured, and included all details

#### Implementation focuses on the following questions:
Did the agent include all expected content from the reference?
Was the information factually correct and contextually relevant?
Was the task or objective fully completed as intended?
Was the structure and tone (for Comms) aligned with the workflow standards

### Whitebox evaluation implementation for SDR+ workflow
It essentially focuses on trace-based evaluation. Given a (user)query and agent thought trail which is generated by processing the user query, the implementation analyses the agent thought trail and returns a score of 0/1

#### Score system:
0: agent thought trail has issues/ is not valid (not useful) <br/>
1: agent thought trail is working correctly is valid (useful)

#### Implementation focuses on the following questions:
1. Was the flow valid? i.e., followed logical needed steps like thought, tool usage, thought, final answer etc
2. Were tools used by the agent?
3. Were the right tools used?
4. Errors seen


### Negative testing evaluation for SDR+ workflow
Makes use of watsonx.governance libraries to run HAP checks on all the content present - input and output of each agent

#### Score system:
0: HAP/HARM/Unethical behavior etc content NOT found <br/>
1: HAP/HARM/Unethical behavior etc content found

#### For cases where wx.gov cannot flag "negative" content: Developed LLM as Judge
#### LLM as Judge Score system: (same as above)
0: content is clean<br/>
1: "negative" content found

#### Implementation:
Inorder to run the integrated codebase locally, you need to build it slightly different since the wx.gov libraries don't work well on macs:

1. Build the fastapi backend separately: `podman build --platform=linux/amd64 -t fastapi_app_image -f Dockerfile .`
2. Replace docker-compose yaml with the given compose yaml and add env variables under 'environment' sections:
```
services:
  fastapi_app:
    container_name: fastapi_app
    platform: linux/amd64
    image: fastapi_app_image
    #volumes:
    #  - ./app:/app
    ports:
      - 3001:3001
    environment:
      - WATSONX_URL=https://us-south.ml.cloud.ibm.com
      - WX_PROJECT_ID=
      - IBM_CLOUD_API_KEY=
      - LLM_JUDGE_API_KEY=
      - WX_PLATFORM=saas
      - WX_USER=''
      - WX_GOV_REGION=eu-de
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - SERVER_URL=http://localhost:3001
    restart: always

  redis:
    container_name: redis
    image: redis:7.2.5-alpine
    restart: always

  celery_worker:
    container_name: celery_worker
    build: .
    #volumes:
    #  - ./app:/app
    command: celery -A app.celery.celery_worker.celery worker --loglevel=info
    environment:
      - WATSONX_URL=https://us-south.ml.cloud.ibm.com
      - WX_PROJECT_ID=
      - WX_PLATFORM=saas
      - WX_USER=''
      - WX_GOV_REGION=eu-de
      - IBM_CLOUD_API_KEY=
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - fastapi_app
      - redis
    restart: always

  flower:
    container_name: flower
    build: .
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    ports:
      - 5556:5555
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - fastapi_app
      - redis
      - celery_worker
    restart: always
```
3. Run to build the rest of the services: `podman-compose build`
4. Run to get the services up and running: `podman-compose up -d`
5. Run to check if all 4 services are up and running: `podman-compose ps`

